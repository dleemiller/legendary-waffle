model:
  d_model: 768
  n_layers: 12
  n_heads: 12
  d_ff: 3072
  dropout: 0.1
  vocab_size: 100  # will be set from tokenizer
  max_path_len: 128
  max_char_len: 48
  predict_path: false  # Disabled - not training on path prediction
  predict_length: true # ONLY objective enabled

data:
  dataset_name: "futo-org/swipe.futo.org"
  train_split: "train"
  val_split: "validation"
  test_split: "test"
  max_path_len: 128
  max_char_len: 48
  char_mask_prob: 1.0      # Not used by PairwiseMaskedCollator
  path_mask_prob: 0.0      # Not used by PairwiseMaskedCollator
  mask_path: true
  num_workers: 4

training:
  learning_rate: 1.0e-5
  min_learning_rate: 1.0e-6
  weight_decay: 0.01
  num_epochs: 40
  warmup_steps: 3600  # More warmup for larger model
  char_loss_weight: 0.0
  path_loss_weight: 0.0
  log_interval: 100
  val_interval: 1000
  save_interval: 1
  keep_n_checkpoints: 2  # Keep best + 2 most recent epoch checkpoints
  log_dir: "logs"
  checkpoint_dir: "checkpoints"
  device: "cuda"
  use_amp: true
  amp_dtype: "bfloat16"
  use_focal_loss: false  # Not used for length-only training
  focal_gamma: 0.0
  use_char_freq_weights: false
  char_weights_path: null
  use_pairwise_masking: true
  pairwise_modality_prob: 1.0              # 100% modality masking
  pairwise_zero_attention_prob: 1.0   # Always zero attention (text/path) for length-only training
  pairwise_inverted_char_prob_heavy: [0.5, 0.7]
  pairwise_inverted_path_prob_heavy: [0.5, 0.7]
  pairwise_inverted_char_prob_light: [0.1, 0.2]
  pairwise_inverted_path_prob_light: [0.1, 0.2]
  contrastive_weight: 0.0
  contrastive_temperature: 0.07
  matryoshka_dims: [64, 128, 384, 768]
  matryoshka_weights: [2.0, 1.5, 1.0, 1.0]
  length_loss_weight: 1.0

  # HuggingFace TrainingArguments (single source for batch size)
  training_args:
    per_device_train_batch_size: 256
    per_device_eval_batch_size: 256
    lr_scheduler_type: "cosine"
