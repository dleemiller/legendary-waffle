model:
  d_model: 768
  n_layers: 12
  n_heads: 12
  d_ff: 3072
  dropout: 0.1
  vocab_size: 100  # will be set from tokenizer
  max_path_len: 128
  max_char_len: 48
  predict_path: false      # Disable path prediction head
  predict_length: false    # Disable length prediction head

data:
  dataset_name: "futo-org/swipe.futo.org"
  train_split: "train"
  val_split: "validation"
  test_split: "test"
  max_path_len: 128
  max_char_len: 48
  char_mask_prob: 1.0     # Random masking probability between 50% and 100%
  path_mask_prob: 0.0            # Disable path masking
  mask_path: false               # Disable path masking
  mask_vocab_only: true          # Only mask a-z, 0-9 (not punctuation or EOS)
  batch_size: 512
  num_workers: 4

training:
  learning_rate: 0.00002         # Lower LR for fine-tuning (2e-5)
  min_learning_rate: 0.000002    # 10% of learning rate (2e-6)
  weight_decay: 0.01
  num_epochs: 10                 # Fewer epochs for fine-tuning
  warmup_steps: 500              # Shorter warmup for fine-tuning

  # Loss weights - ONLY character MLM
  char_loss_weight: 1.0          # ONLY enabled objective
  path_loss_weight: 0.0          # DISABLED
  length_loss_weight: 0.0        # DISABLED
  contrastive_weight: 0.0        # DISABLED

  log_interval: 100
  val_interval: 1000
  save_interval: 1
  keep_n_checkpoints: 2
  log_dir: "logs"
  checkpoint_dir: "checkpoints"
  device: "cuda"
  use_amp: true
  amp_dtype: "bfloat16"

  # Character loss configuration (keep existing)
  use_focal_loss: true
  focal_gamma: 2.0
  use_char_freq_weights: true
  char_weights_path: "checkpoints/char_weights.pt"

  # Disable contrastive learning
  use_pairwise_masking: false    # Use standard MaskedCollator
  pairwise_modality_prob: 0.0
  matryoshka_dims: null
  matryoshka_weights: null
